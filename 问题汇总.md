##文件命名，函数命名很重要！！！！！！！！！命名规范得统一

## 建表(记录特征 模型 分数)


## [【机器学习】k-fold cross validation（k-折叠交叉验证）](https://blog.csdn.net/evillist/article/details/61912827)

### 1、lsa和lda的降维是针对已经用tfidf构建的特征来降维的吗？这个先后顺序是必要的吗？
```
这个先后顺序是必要的哈，LSA和LDA本来是用来提主题特征的，是基于词袋模型，的，所以要先词袋（bow和tfidf），后提主题（LSA或LDA）。
一般机器学习处理NLP问题的时候，都需要先Representation，词袋是NLP里面一种比较常用的Representation方式。
```
### 2、只用word_seg的前提下最好的模型是lr和svm 最高分是svm(c=5)0.774

### 3、跑过的模型，特征没有保存，花费的时间成本太高

### 4、模型融合用的模型太少，模型差异性不够大！模型融合要“好而不同”

### 5、LinerSVM模型没有预测概率的方法

### 6、模型，特征文件太大，需上传到百度云，队友自行下载

### 7、遗传算法调超参？？？？？？？？@SimonSTYL

### 8、如何高效利用资源比结果本身更值得学习        ————范晶晶
                                    
### 9、评分？？？？？？？？？？？？？？

### 10、bagging？？？？？？

### 11、stacking？？？？？？

### 12、SVM(C=0.5)article 比 SVM(C=4)article 效果好  SVM(C=4)article+word_seg 比 SVM(C=0.5)article+word_seg  效果好
    数据的偏移问题，数据的分布发生了变化             ————SimonSTYL

### 13、测试从0.1-100的超参是怎么测的？能否给个代码？？？@SimonSTYL

### 14、预测分数接近100%，明显过拟合

### 15、整体线性模型比树模型效果要好？ 不太理解 @范晶晶

### 16、特征读取、保存方法
```
import pickle
print("1 tfidf特征加载")
f_tf = open('../feature_file/data_w_tfidf.pkl', 'rb')
x_train, y_train, x_test = pickle.load(f_tf)
f_tf.close()
```
```
import pickle
print("3 将lda特征保存至本地")
data = (x_train, y_train, x_test)
f_data = open('../feature_file/data_w_tf(lda).pkl', 'wb')
pickle.dump(data, f_data)
f_data.close()
```

### 17、模型读取、保存方法
```
from sklearn.externals import joblib
print('3 读取模型')
clf2 = joblib.load("lr(c40).m")
```

```
from sklearn.externals import joblib
print('3 保存模型')
joblib.dump(kn, model_path + "KN(n_n19)_data_w_tfidf.m")
```
### 18、神经网络 bachsize不要超过1000

### 19、随机森林

### 20、esemble无法接受LinerSVC

### 21、神经网络的预测函数是predict

### 22、SVM中，距离超平面越远，且正确分类的，得分越高

### 23、SVM中没有predict_proba，需要如下代码
```
svm = joblib.load("svm(c5).pkl")
clf1 = CalibratedClassifierCV(base_estimator=svm,  cv ="prefit" )
clf1.fit(x_train,y_train)
y_test = clf1.predict_proba(x_test)
df_test['proba']=y_test.tolist()
df_result = df_test.loc[:,['id','proba']]
df_result.to_csv('result_proba_svm.csv',index=False)

```

### 24、不用模型，直接拿结果进行投票

### 25、多个模型预测的概率相加，好的模型概率赋予高权重，然后投票

### 26、降维

### 27、嵌入式特征选择（模型输出的权重挑选特征）对我们来说有没有意义？

### 28、tfidf处理后的特征相比其他方式处理的算新的特征，可以一个模型跑多个特征

### 29、tfidf其实已经包含了tf(bow)的信息[tf就是bow，然后乘了个你文本文档频率]

### 30、归一化

### 31、LR_tfidf(lsa)得到的结果才0.58？

### 32、模型训练好之后需不需要之前的特征？
    需要！！！因为特定的特征训练出来的模型，是在该特征分布下分类的，是有依赖的，不同的特征提取和偏重会导致模型的参数不一样

### 33、SVM挑选了888357个特征 ？给个代码 @范晶晶

### 34、稀疏矩阵？？

### 35、concat在合并的时候，需要将特征文件转化为稀疏矩阵

### 36、predict和predict_prob,后者是概率，前者是概率的最大值输出

### 37、希望调用已经训练好的模型或者是输出结果，希望可以不基于同样的特征，比如SVM在tfidf上的效果比较好，LGB在降维特征上比较好

### 38、投票方法：概率相加取最大值；结果取多数。

### 39、拼接特征基础上+自动编码器产生的新特征Ae_ensemble.py发个代码 @范晶晶

### 40、SVM_word_seg+article+len 效果降低 说明补充的特征产生了副作用，干扰了分类器      ———SimonSTYL

### 41、svm挑选word和lr挑选article特征是如何挑选的 发个代码？@范晶晶

### 42、最后0.78199是怎么上的 @范晶晶

### 43、

### 44、











